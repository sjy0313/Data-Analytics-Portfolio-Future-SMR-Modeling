# -*- coding: utf-8 -*-
"""
Created on Thu Jul 25 09:17:24 2024

@author: Shin
"""
# ë‹¤ì¤‘ê³µì„ ì„± VIFê²€ì • ë° íšŒê·€ë¶„ì„ì„ í†µí•´ í™•ì¸ 
# ë‹¤ì¤‘ê³µì„ ì„±(multicollinearity) : í•˜ë‚˜ì˜ ë…ë¦½ë³€ìˆ˜ê°€ ë‹¤ë¥¸ ì—¬ëŸ¬ ê°œì˜ ë…ë¦½ë³€ìˆ˜ë“¤ë¡œ ì˜ ì˜ˆì¸¡ë˜ëŠ” ê²½ìš°
# ë‹¤ì¤‘ê³µì„ ì„±ì´ ìˆìœ¼ë©´,
#ê³„ìˆ˜ ì¶”ì •ì´ ì˜ ë˜ì§€ ì•Šê±°ë‚˜ ë¶ˆì•ˆì •í•´ì ¸ì„œ ë°ì´í„°ê°€ ì•½ê°„ë§Œ ë°”ë€Œì–´ë„ ì¶”ì •ì¹˜ê°€ í¬ê²Œ ë‹¬ë¼ì§ˆ ìˆ˜ ìˆë‹¤
#ê³„ìˆ˜ê°€ í†µê³„ì ìœ¼ë¡œ ìœ ì˜ë¯¸í•˜ì§€ ì•Šì€ ê²ƒì²˜ëŸ¼ ë‚˜ì˜¬ ìˆ˜ ìˆë‹¤
# VIF ê²€ì •ì€ ë‹¤ì¤‘ê³µì„ ì„±ì´ ì¶”ì • ê¸°ìš¸ê¸° ê³„ìˆ˜ì˜ í‘œì¤€ì˜¤ì°¨ë¥¼ ì–¼ë§ˆë‚˜ ì¦ê°€ì‹œì¼°ëŠ”ì§€ë¥¼ ì¸¡ì •í•˜ëŠ” ì§€í‘œ
#ì—„ë°€í•œ ê¸°ì¤€ì€ ì—†ìœ¼ë‚˜ ë³´í†µ 10ë³´ë‹¤ í¬ë©´ ë‹¤ì¤‘ê³µì„ ì„±ì´ ìˆë‹¤ê³  íŒë‹¨(5ë¥¼ ê¸°ì¤€ìœ¼ë¡œ í•˜ê¸°ë„ í•¨)

# df : êµìœ¡_2015_ì „êµ­ (êµìœ¡ë³€ìˆ˜í†µí•©)
# df_p : 2015_ê°œì„ ì†Œë©¸ì§€ìˆ˜ë¥¼'2015~2023ê°œì„ ì†Œë©¸ì§€ìˆ˜'ì—ì„œ ì¶”ì¶œí•˜ì—¬ excelë¡œ ì €ì¥í•˜ì˜€ìŒ. 
import pandas as pd

file_path = "C:/Users/Shin/Documents/Final_Project/Data/êµìœ¡_ì „êµ­/êµìœ¡_ì—°ë„ë³„_ì „êµ­í†µí•©/êµìœ¡/EXCEL/êµìœ¡_2015_ì „êµ­.xlsx"
file_path_1 = "C:/Users/Shin/Documents/Final_Project/Data/êµìœ¡_ì „êµ­/êµìœ¡_ì—°ë„ë³„_ì „êµ­í†µí•©/ê°œì„ ì†Œë©¸ìœ„í—˜ì§€ìˆ˜2015.xlsx"
df = pd.read_excel(file_path, engine='openpyxl')
df_p = pd.read_excel(file_path_1, engine='openpyxl')
    
#%%
#í°íŠ¸ ì„¤ì •
from matplotlib import font_manager, rc
font_path = "c:/Windows/Fonts/malgun.ttf"
font_name = font_manager.FontProperties(fname=font_path).get_name()
rc('font', family=font_name)
#%%

# ìƒê´€ê´€ê³„ ë¶„ì„ 2015 ë…„ë„ êµì›_1ì¸ë‹¹_í•™ìƒìˆ˜ì™€ 2015 ì§€ë°©ì†Œë©¸ì§€ìˆ˜ ìƒê´€ê´€ê³„  : 

'''
''êµì›_1ì¸ë‹¹_í•™ìƒìˆ˜_ìœ ì¹˜ì›', 'êµì›_1ì¸ë‹¹_í•™ìƒìˆ˜_ì´ˆë“±í•™êµ', 'êµì›_1ì¸ë‹¹_í•™ìƒìˆ˜_ì¤‘í•™êµ', 'êµì›_1ì¸ë‹¹_í•™ìƒìˆ˜_ê³ ë“±í•™êµ'
 'ìœ ì¹˜ì›_í•™ê¸‰ë‹¹ í•™ìƒ ìˆ˜ (ëª…)', 'ì´ˆë“±í•™êµ_í•™ê¸‰ë‹¹ í•™ìƒ ìˆ˜ (ëª…)', 'ì¤‘í•™êµ_í•™ê¸‰ë‹¹ í•™ìƒ ìˆ˜ (ëª…)','ê³ ë“±í•™êµ_í•™ê¸‰ë‹¹ í•™ìƒ ìˆ˜ (ëª…)',
 'í•™êµêµê³¼ êµìŠµí•™ì› (ê°œ)', 'í‰ìƒì§ì—… êµìœ¡í•™ì› (ê°œ)', 'ì‚¬ì„¤í•™ì›ë‹¹ í•™ìƒìˆ˜ (ëª…)','ìœ ì¹˜ì›ìƒ ìˆ˜', 'ì´ˆë“±í•™ìƒ ìˆ˜'
'''
import matplotlib.pyplot as plt
import seaborn as sns
import pandas as pd
import statsmodels.api as sm
#%%
# 2015ì§€ë°©ì†Œë©¸ìœ„í—˜ì§€ìˆ˜ í¬í•¨ 
'''
df['2015'] = df_p['2015']

sns.pairplot(df[['êµì›_1ì¸ë‹¹_í•™ìƒìˆ˜_ìœ ì¹˜ì›', 'êµì›_1ì¸ë‹¹_í•™ìƒìˆ˜_ì´ˆë“±í•™êµ', 'êµì›_1ì¸ë‹¹_í•™ìƒìˆ˜_ì¤‘í•™êµ', 'êµì›_1ì¸ë‹¹_í•™ìƒìˆ˜_ê³ ë“±í•™êµ', '2015']])
plt.show()
'''
#%%

sns.pairplot(df[['êµì›_1ì¸ë‹¹_í•™ìƒìˆ˜_ìœ ì¹˜ì›', 'êµì›_1ì¸ë‹¹_í•™ìƒìˆ˜_ì´ˆë“±í•™êµ', 'êµì›_1ì¸ë‹¹_í•™ìƒìˆ˜_ì¤‘í•™êµ', 'êµì›_1ì¸ë‹¹_í•™ìƒìˆ˜_ê³ ë“±í•™êµ']])
plt.show()
# ë§ì€ í†µê³„ ì†Œí”„íŠ¸ì›¨ì–´ì™€ ë¼ì´ë¸ŒëŸ¬ë¦¬ëŠ” ì ˆí¸ì„ ìë™ìœ¼ë¡œ í¬í•¨í•˜ì§€ë§Œ, 
#statsmodelsì˜ OLS (Ordinary Least Squares) í•¨ìˆ˜ëŠ” ê¸°ë³¸ì ìœ¼ë¡œ ë…ë¦½ ë³€ìˆ˜ í–‰ë ¬ ğ‘‹ì— ì ˆí¸ì„ í¬í•¨ì‹œí‚¤ì§€ ì•ŠìŠµë‹ˆë‹¤. 
#ë”°ë¼ì„œ, ì§ì ‘ ì ˆí¸ì„ ì¶”ê°€í•´ ì£¼ì–´ì•¼ í•©ë‹ˆë‹¤.
df['intercept'] = 1 #(ì ˆí¸) 
model = sm.OLS(df_p['2015'], df[['êµì›_1ì¸ë‹¹_í•™ìƒìˆ˜_ìœ ì¹˜ì›', 'êµì›_1ì¸ë‹¹_í•™ìƒìˆ˜_ì´ˆë“±í•™êµ', 'êµì›_1ì¸ë‹¹_í•™ìƒìˆ˜_ì¤‘í•™êµ', 'êµì›_1ì¸ë‹¹_í•™ìƒìˆ˜_ê³ ë“±í•™êµ']])


results = model.fit()
print(results.summary())
'''
OLS Regression Results                                
=======================================================================================
Dep. Variable:                   2015   R-squared (uncentered):                   0.494 : ëª¨ë¸ì´ ì¢…ì† ë³€ìˆ˜ì˜ ë³€ë™ì„±ì„ ì–¼ë§ˆë‚˜ ì„¤ëª…í•˜ëŠ”ì§€ë¥¼ ë‚˜íƒ€ëƒ…ë‹ˆë‹¤.
Model:                            OLS   Adj. R-squared (uncentered):              0.485 : ìˆ˜ì •ëœ R-squaredë¡œ, ëª¨ë¸ì˜ ì„¤ëª…ë ¥ì„ ë³€ìˆ˜ì˜ ê°œìˆ˜ì— ëŒ€í•´ ì¡°ì •í•œ ê°’
Method:                 Least Squares   F-statistic:                              54.95 : F-statisticì€ ëª¨ë¸ì˜ ì„¤ëª…ë ¥ì´ í†µê³„ì ìœ¼ë¡œ ìœ ì˜ë¯¸í•œì§€ ê²€ì •
Date:                Thu, 25 Jul 2024   Prob (F-statistic):                    2.84e-32 : ë§¤ìš° ë‚®ì€ p-value (0.000000000000000000000000000000284)ë¡œ, ëª¨ë¸ì´ ìœ ì˜ë¯¸í•˜ë‹¤ëŠ” ê²ƒì„ ê°•í•˜ê²Œ ì‹œì‚¬
Time:                        10:01:11   Log-Likelihood:                         -389.25
No. Observations:                 229   AIC:                                      786.5
Df Residuals:                     225   BIC:                                      800.2
Df Model:                           4                                                  
Covariance Type:            nonrobust                                                  
===================================================================================
                                 coef    std err          t      P>|t|      [0.025      0.975] 
-----------------------------------------------------------------------------------
êµì›_1ì¸ë‹¹_í•™ìƒìˆ˜_ìœ ì¹˜ì›      0.0969      0.049      1.981      #0.049       0.001       0.193
êµì›_1ì¸ë‹¹_í•™ìƒìˆ˜_ì´ˆë“±í•™êµ    -0.0220      0.068     -0.327      0.744      -0.155       0.111
êµì›_1ì¸ë‹¹_í•™ìƒìˆ˜_ì¤‘í•™êµ      0.0341      0.069      0.495      0.621      -0.102       0.170
êµì›_1ì¸ë‹¹_í•™ìƒìˆ˜_ê³ ë“±í•™êµ     0.0032      0.045      0.070      0.944      -0.086       0.093
==============================================================================
Omnibus:                       67.987   Durbin-Watson:                   1.299 : ì´ í†µê³„ëŸ‰ì€ ì”ì°¨ì˜ ìê¸°ìƒê´€ì„ ì¸¡ì • ê°’ì´ 2ì— ê°€ê¹Œìš¸ìˆ˜ë¡ ìê¸°ìƒê´€ì´ ì—†ìŒì„ ì˜ë¯¸í•©ë‹ˆë‹¤ 1.299ëŠ” ì•½ê°„ì˜ ì–‘ì˜ ìê¸°ìƒê´€ì´ ì¡´ì¬í•  ìˆ˜ ìˆìŒì„ ì‹œì‚¬
Prob(Omnibus):                  0.000   Jarque-Bera (JB):              132.636
Skew:                           1.500   Prob(JB):                     1.58e-29
Kurtosis:                       5.214   Cond. No.                         26.1
==============================================================================

Notes:
[1] RÂ² is computed without centering (uncentered) since the model does not contain a constant.
[2] Standard Errors assume that the covariance matrix of the errors is correctly specified.
'''
# ê·€ë¬´ê°€ì„¤ì€ ì°¨ì´/ì˜í–¥ë ¥/ì—°ê´€ì„±ì´ ì—†ë‹¤ê³  ì„¤ì •í•˜ê³  ëŒ€ë¦½ê°€ì„¤ì€ ì°¨ì´/ì˜í–¥ë ¥/ì—°ê´€ì„±ì´ ìˆë‹¤ê³  ì„¤ì •í•œë‹¤  
# p-value ê°’ì´ 0.05ë¯¸ë§Œì˜ ì˜ë¯¸ëŠ” í‘œë³¸ì˜ í†µê³„ì¹˜ê°€ ê·€ë¬´ê°€ì„¤ê³¼ ê°™ì´ ë‚˜ì˜¬ í™•ë¥ ì´ 5%ë¯¸ë§Œ ì¦‰, ê·€ë¬´ê°€ì„¤ì„ ê¸°ê°í•˜ê³  ëŒ€ë¦½ê°€ì„¤ì„ ì±„íƒ
'''
Coefficients and p-values:

êµì›_1ì¸ë‹¹_í•™ìƒìˆ˜_ìœ ì¹˜ì›: 0.0969 (p-value: 0.049)
ìœ ì˜ë¯¸í•œ ê²°ê³¼ (p-value < 0.05). ìœ ì¹˜ì› êµì› 1ì¸ë‹¹ í•™ìƒ ìˆ˜ê°€ ì¦ê°€í•  ë•Œ, 2015ë…„ ì¢…ì† ë³€ìˆ˜ ê°’ì´ ì¦ê°€í•©ë‹ˆë‹¤.
êµì›_1ì¸ë‹¹_í•™ìƒìˆ˜_ì´ˆë“±í•™êµ: -0.0220 (p-value: 0.744)
ìœ ì˜ë¯¸í•˜ì§€ ì•ŠìŒ (p-value > 0.05). ì´ˆë“±í•™êµ êµì› 1ì¸ë‹¹ í•™ìƒ ìˆ˜ì™€ 2015ë…„ ì¢…ì† ë³€ìˆ˜ ê°„ì—ëŠ” ìœ ì˜ë¯¸í•œ ê´€ê³„ê°€ ì—†ìŠµë‹ˆë‹¤.
êµì›_1ì¸ë‹¹_í•™ìƒìˆ˜_ì¤‘í•™êµ: 0.0341 (p-value: 0.621)
ìœ ì˜ë¯¸í•˜ì§€ ì•ŠìŒ. ì¤‘í•™êµ êµì› 1ì¸ë‹¹ í•™ìƒ ìˆ˜ì™€ 2015ë…„ ì¢…ì† ë³€ìˆ˜ ê°„ì—ëŠ” ìœ ì˜ë¯¸í•œ ê´€ê³„ê°€ ì—†ìŠµë‹ˆë‹¤.
êµì›_1ì¸ë‹¹_í•™ìƒìˆ˜_ê³ ë“±í•™êµ: 0.0032 (p-value: 0.944)
ìœ ì˜ë¯¸í•˜ì§€ ì•ŠìŒ. ê³ ë“±í•™êµ êµì› 1ì¸ë‹¹ í•™ìƒ ìˆ˜ì™€ 2015ë…„ ì¢…ì† ë³€ìˆ˜ ê°„ì—ëŠ” ìœ ì˜ë¯¸í•œ ê´€ê³„ê°€ ì—†ìŠµë‹ˆë‹¤.'''

'''
ê²°ë¡ 
ìœ ì¹˜ì› êµì› 1ì¸ë‹¹ í•™ìƒ ìˆ˜ëŠ” ì¢…ì† ë³€ìˆ˜ì— ìœ ì˜ë¯¸í•œ ì˜í–¥ì„ ë¯¸ì¹˜ëŠ” ê²ƒìœ¼ë¡œ ë‚˜íƒ€ë‚¬ìŠµë‹ˆë‹¤. ì´ëŠ” ìœ ì¹˜ì› êµì› 1ì¸ë‹¹ í•™ìƒ ìˆ˜ê°€ ì¦ê°€í• ìˆ˜ë¡ ì¢…ì† ë³€ìˆ˜ì˜ ê°’ë„ ì¦ê°€í•˜ëŠ” ê²½í–¥ì´ ìˆìŒì„ ì˜ë¯¸í•©ë‹ˆë‹¤.
ê·¸ëŸ¬ë‚˜ ì´ˆë“±í•™êµ, ì¤‘í•™êµ, ê³ ë“±í•™êµì˜ ê²½ìš°, êµì› 1ì¸ë‹¹ í•™ìƒ ìˆ˜ì™€ ì¢…ì† ë³€ìˆ˜ ê°„ì˜ ìœ ì˜ë¯¸í•œ ê´€ê³„ëŠ” ë°œê²¬ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.
ì „ë°˜ì ìœ¼ë¡œ ëª¨ë¸ì€ 2015ë…„ ë°ì´í„°ì˜ ì•½ 49.4%ë¥¼ ì„¤ëª…í•  ìˆ˜ ìˆì§€ë§Œ, ì¼ë¶€ ë…ë¦½ ë³€ìˆ˜ì˜ ì˜í–¥ì€ í†µê³„ì ìœ¼ë¡œ ìœ ì˜ë¯¸í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤.'''
#%%
#VIF ìˆ˜ì¹˜ë¥¼ í™•ì¸í•˜ëŠ” python ì½”ë“œ:
'''
VIF ê°’ì´ (10 ì´ìƒì˜ ê°’) ê²½ìš°, ë‹¤ì¤‘ê³µì„ ì„±ì„ ê³ ë ¤í•˜ì—¬ í•´ë‹¹ ë³€ìˆ˜ë¥¼ ì ì ˆíˆ ì œì™¸ í•˜ì˜€ì§€ë§Œ
 ë³¸ ì—°êµ¬ì—ì„œëŠ” ë¨¸ì‹ ëŸ¬ë‹ ë¶„ë¥˜ ëª¨ë¸(K-Fold)í™œìš© í•˜ì—¬ ë³€ìˆ˜ ê°„ ìƒê´€ê´€ê³„ì— ì˜í–¥ì„ ì¤„ì´ê³ ,
 ìµœëŒ€í•œ ë§ì€ ë…ë¦½ë³€ìˆ˜ë“¤ì„ ê³ ë ¤í•˜ì—¬ ë¶„ë¥˜ ëª¨ë¸ì˜ ì •í™•ë„ë¥¼ ë†’ì´ê³ ì í•˜ì˜€ë‹¤
'''
from statsmodels.stats.outliers_influence import variance_inflation_factor


X_train = df[['êµì›_1ì¸ë‹¹_í•™ìƒìˆ˜_ìœ ì¹˜ì›', 'êµì›_1ì¸ë‹¹_í•™ìƒìˆ˜_ì´ˆë“±í•™êµ', 'êµì›_1ì¸ë‹¹_í•™ìƒìˆ˜_ì¤‘í•™êµ', 'êµì›_1ì¸ë‹¹_í•™ìƒìˆ˜_ê³ ë“±í•™êµ']]
def feature_engineering_XbyVIF(X_train):
    vif = pd.DataFrame()
    vif['VIF_Factor'] = [variance_inflation_factor(X_train.values, i)
                         for i in range(X_train.shape[1])]
    vif['Feature'] = X_train.columns
    return vif
vif = feature_engineering_XbyVIF(X_train)
print(vif)
'''
   VIF_Factor          Feature
0   42.764089   êµì›_1ì¸ë‹¹_í•™ìƒìˆ˜_ìœ ì¹˜ì›
1   92.992490  êµì›_1ì¸ë‹¹_í•™ìƒìˆ˜_ì´ˆë“±í•™êµ
2   87.481160   êµì›_1ì¸ë‹¹_í•™ìƒìˆ˜_ì¤‘í•™êµ
3   37.835847  êµì›_1ì¸ë‹¹_í•™ìƒìˆ˜_ê³ ë“±í•™êµ'''
#%%
# ìƒê´€ê´€ê³„ ë¶„ì„ 2015 ë…„ë„ êµì›_1ì¸ë‹¹_í•™ìƒìˆ˜ì™€ 2015 ì§€ë°©ì†Œë©¸ì§€ìˆ˜ ìƒê´€ê´€ê³„:
    
sns.pairplot(df[[    'ìœ ì¹˜ì›_í•™ê¸‰ë‹¹ í•™ìƒ ìˆ˜ (ëª…)', 'ì´ˆë“±í•™êµ_í•™ê¸‰ë‹¹ í•™ìƒ ìˆ˜ (ëª…)', 'ì¤‘í•™êµ_í•™ê¸‰ë‹¹ í•™ìƒ ìˆ˜ (ëª…)','ê³ ë“±í•™êµ_í•™ê¸‰ë‹¹ í•™ìƒ ìˆ˜ (ëª…)']])
plt.show()
# ë§ì€ í†µê³„ ì†Œí”„íŠ¸ì›¨ì–´ì™€ ë¼ì´ë¸ŒëŸ¬ë¦¬ëŠ” ì ˆí¸ì„ ìë™ìœ¼ë¡œ í¬í•¨í•˜ì§€ë§Œ, 
#statsmodelsì˜ OLS (Ordinary Least Squares) í•¨ìˆ˜ëŠ” ê¸°ë³¸ì ìœ¼ë¡œ ë…ë¦½ ë³€ìˆ˜ í–‰ë ¬ ğ‘‹ì— ì ˆí¸ì„ í¬í•¨ì‹œí‚¤ì§€ ì•ŠìŠµë‹ˆë‹¤. 
#ë”°ë¼ì„œ, ì§ì ‘ ì ˆí¸ì„ ì¶”ê°€í•´ ì£¼ì–´ì•¼ í•©ë‹ˆë‹¤.
df['intercept'] = 1 #(ì ˆí¸) 
model = sm.OLS(df_p['2015'], df[['ìœ ì¹˜ì›_í•™ê¸‰ë‹¹ í•™ìƒ ìˆ˜ (ëª…)', 'ì´ˆë“±í•™êµ_í•™ê¸‰ë‹¹ í•™ìƒ ìˆ˜ (ëª…)', 'ì¤‘í•™êµ_í•™ê¸‰ë‹¹ í•™ìƒ ìˆ˜ (ëª…)','ê³ ë“±í•™êµ_í•™ê¸‰ë‹¹ í•™ìƒ ìˆ˜ (ëª…)']])

results = model.fit()
print(results.summary())
'''
                                 OLS Regression Results                                
=======================================================================================
Dep. Variable:                   2015   R-squared (uncentered):                   0.495
Model:                            OLS   Adj. R-squared (uncentered):              0.486
Method:                 Least Squares   F-statistic:                              55.18
Date:                Thu, 25 Jul 2024   Prob (F-statistic):                    2.26e-32
Time:                        10:43:07   Log-Likelihood:                         -389.02
No. Observations:                 229   AIC:                                      786.0
Df Residuals:                     225   BIC:                                      799.8
Df Model:                           4                                                  
Covariance Type:            nonrobust                                                  
=====================================================================================
                                 coef    std err          t      P>|t|      [0.025      0.975]
-------------------------------------------------------------------------------------
ìœ ì¹˜ì›_í•™ê¸‰ë‹¹ í•™ìƒ ìˆ˜ (ëª…)      0.0640      0.037      1.734      0.084      -0.009       0.137
ì´ˆë“±í•™êµ_í•™ê¸‰ë‹¹ í•™ìƒ ìˆ˜ (ëª…)    -0.0163      0.041     -0.401      0.689      -0.097       0.064
ì¤‘í•™êµ_í•™ê¸‰ë‹¹ í•™ìƒ ìˆ˜ (ëª…)     -0.0041      0.036     -0.114      0.909      -0.075       0.067
ê³ ë“±í•™êµ_í•™ê¸‰ë‹¹ í•™ìƒ ìˆ˜ (ëª…)     0.0211      0.022      0.941      0.348      -0.023       0.065
==============================================================================
Omnibus:                       74.067   Durbin-Watson:                   1.285
Prob(Omnibus):                  0.000   Jarque-Bera (JB):              155.278
Skew:                           1.590   Prob(JB):                     1.91e-34
Kurtosis:                       5.481   Cond. No.                         28.1
==============================================================================
# Cond. No. (Condition Number): 28.1

ë…ë¦½ ë³€ìˆ˜ ê°„ì˜ ë‹¤ì¤‘ê³µì„ ì„±ì„ ë‚˜íƒ€ë‚´ëŠ” ì§€í‘œì…ë‹ˆë‹¤. ê°’ì´ 30 ì´ìƒì¼ ê²½ìš° ë‹¤ì¤‘ê³µì„ ì„± ë¬¸ì œê°€ ìˆì„ ìˆ˜ ìˆì§€ë§Œ, í˜„ì¬ ê°’ì€ í¬ê²Œ ë¬¸ì œê°€ ë˜ëŠ” ìˆ˜ì¤€ì€ ì•„ë‹™ë‹ˆë‹¤.
Notes:
[1] RÂ² is computed without centering (uncentered) since the model does not contain a constant.
[2] Standard Errors assume that the covariance matrix of the errors is correctly specified.


Coefficients and p-values:
ìœ ì¹˜ì›_í•™ê¸‰ë‹¹ í•™ìƒ ìˆ˜ (ëª…): 0.0640 (p-value: 0.084)
p-valueê°€ 0.05ë³´ë‹¤ í¬ë¯€ë¡œ ìœ ì˜ë¯¸í•˜ì§€ ì•Šë‹¤ê³  íŒë‹¨ë©ë‹ˆë‹¤. ê·¸ëŸ¬ë‚˜ ê³„ìˆ˜ê°€ ì–‘ìˆ˜ë¡œ, ìœ ì¹˜ì› í•™ê¸‰ë‹¹ í•™ìƒ ìˆ˜ê°€ ì¦ê°€í•  ë•Œ ì¢…ì† ë³€ìˆ˜ì˜ ê°’ì´ ì•½ê°„ ì¦ê°€í•˜ëŠ” ê²½í–¥ì´ ìˆìŠµë‹ˆë‹¤.
ì´ˆë“±í•™êµ_í•™ê¸‰ë‹¹ í•™ìƒ ìˆ˜ (ëª…): -0.0163 (p-value: 0.689)
ìœ ì˜ë¯¸í•˜ì§€ ì•ŠìŒ (p-value > 0.05). ì´ˆë“±í•™êµ í•™ê¸‰ë‹¹ í•™ìƒ ìˆ˜ì™€ ì¢…ì† ë³€ìˆ˜ ê°„ì˜ ìœ ì˜ë¯¸í•œ ê´€ê³„ê°€ ì—†ìŒ.
ì¤‘í•™êµ_í•™ê¸‰ë‹¹ í•™ìƒ ìˆ˜ (ëª…): -0.0041 (p-value: 0.909)
ìœ ì˜ë¯¸í•˜ì§€ ì•ŠìŒ. ì¤‘í•™êµ í•™ê¸‰ë‹¹ í•™ìƒ ìˆ˜ì™€ ì¢…ì† ë³€ìˆ˜ ê°„ì˜ ìœ ì˜ë¯¸í•œ ê´€ê³„ê°€ ì—†ìŒ.
ê³ ë“±í•™êµ_í•™ê¸‰ë‹¹ í•™ìƒ ìˆ˜ (ëª…): 0.0211 (p-value: 0.348)
ìœ ì˜ë¯¸í•˜ì§€ ì•ŠìŒ. ê³ ë“±í•™êµ í•™ê¸‰ë‹¹ í•™ìƒ ìˆ˜ì™€ ì¢…ì† ë³€ìˆ˜ ê°„ì˜ ìœ ì˜ë¯¸í•œ ê´€ê³„ê°€ ì—†ìŒ.

ê²°ë¡ 
ì „ì²´ ëª¨ë¸ì€ í†µê³„ì ìœ¼ë¡œ ìœ ì˜ë¯¸í•˜ì§€ë§Œ, ê°œë³„ ë…ë¦½ ë³€ìˆ˜ë“¤ì€ ëŒ€ë¶€ë¶„ ìœ ì˜ë¯¸í•˜ì§€ ì•Šìœ¼ë©°, ì´ëŠ” ë…ë¦½ ë³€ìˆ˜ë“¤ì´ ì¢…ì† ë³€ìˆ˜ì— ë¯¸ì¹˜ëŠ” ì˜í–¥ì´ í¬ì§€ ì•ŠìŒì„ ì‹œì‚¬í•©ë‹ˆë‹¤.
ìœ ì¹˜ì› í•™ê¸‰ë‹¹ í•™ìƒ ìˆ˜ê°€ ì¢…ì† ë³€ìˆ˜ì— ì•½ê°„ì˜ ê¸ì •ì  ì˜í–¥ì„ ë¯¸ì¹  ê°€ëŠ¥ì„±ì´ ìˆì§€ë§Œ, ì´ëŠ” í†µê³„ì ìœ¼ë¡œ ìœ ì˜ë¯¸í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤.
ì”ì°¨ì˜ ì •ê·œì„±ì´ ë¶€ì¡±í•˜ê³ , ì•½ê°„ì˜ ìê¸°ìƒê´€ì´ ìˆì„ ìˆ˜ ìˆìŠµë‹ˆë‹¤.'''
#%%
from statsmodels.stats.outliers_influence import variance_inflation_factor
X_train = df[['ìœ ì¹˜ì›_í•™ê¸‰ë‹¹ í•™ìƒ ìˆ˜ (ëª…)', 'ì´ˆë“±í•™êµ_í•™ê¸‰ë‹¹ í•™ìƒ ìˆ˜ (ëª…)', 'ì¤‘í•™êµ_í•™ê¸‰ë‹¹ í•™ìƒ ìˆ˜ (ëª…)','ê³ ë“±í•™êµ_í•™ê¸‰ë‹¹ í•™ìƒ ìˆ˜ (ëª…)']]
def feature_engineering_XbyVIF(X_train):
    vif = pd.DataFrame()
    vif['VIF_Factor'] = [variance_inflation_factor(X_train.values, i)
                         for i in range(X_train.shape[1])]
    vif['Feature'] = X_train.columns
    return vif
vif = feature_engineering_XbyVIF(X_train)
print(vif)   
'''
  VIF_Factor            Feature
0   55.828692   ìœ ì¹˜ì›_í•™ê¸‰ë‹¹ í•™ìƒ ìˆ˜ (ëª…)
1   81.191601  ì´ˆë“±í•™êµ_í•™ê¸‰ë‹¹ í•™ìƒ ìˆ˜ (ëª…)
2  109.096652   ì¤‘í•™êµ_í•™ê¸‰ë‹¹ í•™ìƒ ìˆ˜ (ëª…)
3   50.853184  ê³ ë“±í•™êµ_í•™ê¸‰ë‹¹ í•™ìƒ ìˆ˜ (ëª…)'''
#%%
# ìƒê´€ê´€ê³„ ë¶„ì„ 2015 ë…„ë„ ì‚¬ì„¤í•™ì›ê³¼ 2015 ì§€ë°©ì†Œë©¸ì§€ìˆ˜ ìƒê´€ê´€ê³„:
    
#'í•™êµêµê³¼ êµìŠµí•™ì› (ê°œ)', 'í‰ìƒì§ì—… êµìœ¡í•™ì› (ê°œ)', 'ì‚¬ì„¤í•™ì›ë‹¹ í•™ìƒìˆ˜ (ëª…)','ìœ ì¹˜ì›ìƒ ìˆ˜', 'ì´ˆë“±í•™ìƒ ìˆ˜'   
 
sns.pairplot(df[['í•™êµêµê³¼ êµìŠµí•™ì› (ê°œ)', 'í‰ìƒì§ì—… êµìœ¡í•™ì› (ê°œ)', 'ì‚¬ì„¤í•™ì›ë‹¹ í•™ìƒìˆ˜ (ëª…)']])
plt.show()
# ë§ì€ í†µê³„ ì†Œí”„íŠ¸ì›¨ì–´ì™€ ë¼ì´ë¸ŒëŸ¬ë¦¬ëŠ” ì ˆí¸ì„ ìë™ìœ¼ë¡œ í¬í•¨í•˜ì§€ë§Œ, 
#statsmodelsì˜ OLS (Ordinary Least Squares) í•¨ìˆ˜ëŠ” ê¸°ë³¸ì ìœ¼ë¡œ ë…ë¦½ ë³€ìˆ˜ í–‰ë ¬ ğ‘‹ì— ì ˆí¸ì„ í¬í•¨ì‹œí‚¤ì§€ ì•ŠìŠµë‹ˆë‹¤. 
#ë”°ë¼ì„œ, ì§ì ‘ ì ˆí¸ì„ ì¶”ê°€í•´ ì£¼ì–´ì•¼ í•©ë‹ˆë‹¤.
df['intercept'] = 1 #(ì ˆí¸) 
model = sm.OLS(df_p['2015'], df[['í•™êµêµê³¼ êµìŠµí•™ì› (ê°œ)', 'í‰ìƒì§ì—… êµìœ¡í•™ì› (ê°œ)', 'ì‚¬ì„¤í•™ì›ë‹¹ í•™ìƒìˆ˜ (ëª…)']])

results = model.fit()
print(results.summary())
'''
    OLS Regression Results                                
=======================================================================================
Dep. Variable:                   2015   R-squared (uncentered):                   0.172
Model:                            OLS   Adj. R-squared (uncentered):              0.161
Method:                 Least Squares   F-statistic:                              15.68
Date:                Thu, 25 Jul 2024   Prob (F-statistic):                    2.68e-09
Time:                        10:53:39   Log-Likelihood:                         -445.64
No. Observations:                 229   AIC:                                      897.3
Df Residuals:                     226   BIC:                                      907.6
Df Model:                           3                                                  
Covariance Type:            nonrobust                                                  
=================================================================================
                             coef    std err          t      P>|t|      [0.025      0.975]
---------------------------------------------------------------------------------
í•™êµêµê³¼ êµìŠµí•™ì› (ê°œ)     0.0001      0.000      0.449      0.654      -0.000       0.001
í‰ìƒì§ì—… êµìœ¡í•™ì› (ê°œ)     0.0039      0.003      1.330      0.185      -0.002       0.010
ì‚¬ì„¤í•™ì›ë‹¹ í•™ìƒìˆ˜ (ëª…)     0.0029      0.001      4.997      0.000       0.002       0.004
==============================================================================
Omnibus:                       39.290   Durbin-Watson:                   0.946
Prob(Omnibus):                  0.000   Jarque-Bera (JB):              115.165
Skew:                           0.708   Prob(JB):                     9.82e-26
Kurtosis:                       6.172   Cond. No.                         24.8
==============================================================================

Notes:
[1] RÂ² is computed without centering (uncentered) since the model does not contain a constant.
[2] Standard Errors assume that the covariance matrix of the errors is correctly specified.'''



#%%
from statsmodels.stats.outliers_influence import variance_inflation_factor
X_train = df[['í•™êµêµê³¼ êµìŠµí•™ì› (ê°œ)', 'í‰ìƒì§ì—… êµìœ¡í•™ì› (ê°œ)', 'ì‚¬ì„¤í•™ì›ë‹¹ í•™ìƒìˆ˜ (ëª…)']]
def feature_engineering_XbyVIF(X_train):
    vif = pd.DataFrame()
    vif['VIF_Factor'] = [variance_inflation_factor(X_train.values, i)
                         for i in range(X_train.shape[1])]
    vif['Feature'] = X_train.columns
    return vif
vif = feature_engineering_XbyVIF(X_train)
print(vif)   
'''
VIF_Factor        Feature
0    5.593359  í•™êµêµê³¼ êµìŠµí•™ì› (ê°œ)
1    5.592409  í‰ìƒì§ì—… êµìœ¡í•™ì› (ê°œ)
2    1.013003  ì‚¬ì„¤í•™ì›ë‹¹ í•™ìƒìˆ˜ (ëª…)'''
#%%
# ìƒê´€ê´€ê³„ ë¶„ì„ 2015 ë…„ë„ ì‚¬ì„¤í•™ì›ê³¼ 2015 ì§€ë°©ì†Œë©¸ì§€ìˆ˜ ìƒê´€ê´€ê³„:

'ìœ ì¹˜ì›ìƒ ìˆ˜', 'ì´ˆë“±í•™ìƒ ìˆ˜' 

sns.pairplot(df[['ìœ ì¹˜ì›ìƒ ìˆ˜', 'ì´ˆë“±í•™ìƒ ìˆ˜']])
plt.show()
# ë§ì€ í†µê³„ ì†Œí”„íŠ¸ì›¨ì–´ì™€ ë¼ì´ë¸ŒëŸ¬ë¦¬ëŠ” ì ˆí¸ì„ ìë™ìœ¼ë¡œ í¬í•¨í•˜ì§€ë§Œ, 
#statsmodelsì˜ OLS (Ordinary Least Squares) í•¨ìˆ˜ëŠ” ê¸°ë³¸ì ìœ¼ë¡œ ë…ë¦½ ë³€ìˆ˜ í–‰ë ¬ ğ‘‹ì— ì ˆí¸ì„ í¬í•¨ì‹œí‚¤ì§€ ì•ŠìŠµë‹ˆë‹¤. 
#ë”°ë¼ì„œ, ì§ì ‘ ì ˆí¸ì„ ì¶”ê°€í•´ ì£¼ì–´ì•¼ í•©ë‹ˆë‹¤.
df['intercept'] = 1 #(ì ˆí¸) 
model = sm.OLS(df_p['2015'], df[['ìœ ì¹˜ì›ìƒ ìˆ˜', 'ì´ˆë“±í•™ìƒ ìˆ˜']])

results = model.fit()
print(results.summary())
'''
OLS Regression Results                                
=======================================================================================
Dep. Variable:                   2015   R-squared (uncentered):                   0.241
Model:                            OLS   Adj. R-squared (uncentered):              0.234
Method:                 Least Squares   F-statistic:                              36.00
Date:                Thu, 25 Jul 2024   Prob (F-statistic):                    2.63e-14
Time:                        11:15:44   Log-Likelihood:                         -435.75
No. Observations:                 229   AIC:                                      875.5
Df Residuals:                     227   BIC:                                      882.4
Df Model:                           2                                                  
Covariance Type:            nonrobust                                                  
==============================================================================
                     coef    std err          t      P>|t|      [0.025      0.975]
------------------------------------------------------------------------------
ìœ ì¹˜ì›ìƒ ìˆ˜     -4.664e-05   9.68e-05     -0.482      0.630      -0.000       0.000
ì´ˆë“±í•™ìƒ ìˆ˜      6.436e-05   2.53e-05      2.540      0.012    1.44e-05       0.000
==============================================================================
Omnibus:                       39.784   Durbin-Watson:                   1.134
Prob(Omnibus):                  0.000   Jarque-Bera (JB):               70.075
Skew:                           0.918   Prob(JB):                     6.07e-16
Kurtosis:                       4.994   Cond. No.                         16.6
==============================================================================

Notes:
[1] RÂ² is computed without centering (uncentered) since the model does not contain a constant.
[2] Standard Errors assume that the covariance matrix of the errors is correctly specified.'''
#%%
from statsmodels.stats.outliers_influence import variance_inflation_factor
X_train = df[['ìœ ì¹˜ì›ìƒ ìˆ˜', 'ì´ˆë“±í•™ìƒ ìˆ˜']]
def feature_engineering_XbyVIF(X_train):
    vif = pd.DataFrame()
    vif['VIF_Factor'] = [variance_inflation_factor(X_train.values, i)
                         for i in range(X_train.shape[1])]
    vif['Feature'] = X_train.columns
    return vif
vif = feature_engineering_XbyVIF(X_train)
print(vif)   
'''
 VIF_Factor Feature
0    16.69906  ìœ ì¹˜ì›ìƒ ìˆ˜
1    16.69906  ì´ˆë“±í•™ìƒ ìˆ˜
'''
#%%
# ìƒê´€ê´€ê³„ ë¶„ì„ 2015 ë…„ë„êµìœ¡ë³€ìˆ˜ í†µí•©ê³¼ 2015 ì§€ë°©ì†Œë©¸ì§€ìˆ˜ ìƒê´€ê´€ê³„:
'''
   'êµì›_1ì¸ë‹¹_í•™ìƒìˆ˜_ìœ ì¹˜ì›', 'êµì›_1ì¸ë‹¹_í•™ìƒìˆ˜_ì´ˆë“±í•™êµ', 'êµì›_1ì¸ë‹¹_í•™ìƒìˆ˜_ì¤‘í•™êµ', 'êµì›_1ì¸ë‹¹_í•™ìƒìˆ˜_ê³ ë“±í•™êµ',
    'ìœ ì¹˜ì›_í•™ê¸‰ë‹¹ í•™ìƒ ìˆ˜ (ëª…)', 'ì´ˆë“±í•™êµ_í•™ê¸‰ë‹¹ í•™ìƒ ìˆ˜ (ëª…)', 'ì¤‘í•™êµ_í•™ê¸‰ë‹¹ í•™ìƒ ìˆ˜ (ëª…)','ê³ ë“±í•™êµ_í•™ê¸‰ë‹¹ í•™ìƒ ìˆ˜ (ëª…)',
    'í•™êµêµê³¼ êµìŠµí•™ì› (ê°œ)', 'í‰ìƒì§ì—… êµìœ¡í•™ì› (ê°œ)', 'ì‚¬ì„¤í•™ì›ë‹¹ í•™ìƒìˆ˜ (ëª…)','ìœ ì¹˜ì›ìƒ ìˆ˜', 'ì´ˆë“±í•™ìƒ ìˆ˜' 
    '''
    
sns.pairplot(df[['êµì›_1ì¸ë‹¹_í•™ìƒìˆ˜_ìœ ì¹˜ì›', 'êµì›_1ì¸ë‹¹_í•™ìƒìˆ˜_ì´ˆë“±í•™êµ', 'êµì›_1ì¸ë‹¹_í•™ìƒìˆ˜_ì¤‘í•™êµ', 'êµì›_1ì¸ë‹¹_í•™ìƒìˆ˜_ê³ ë“±í•™êµ',
 'ìœ ì¹˜ì›_í•™ê¸‰ë‹¹ í•™ìƒ ìˆ˜ (ëª…)', 'ì´ˆë“±í•™êµ_í•™ê¸‰ë‹¹ í•™ìƒ ìˆ˜ (ëª…)', 'ì¤‘í•™êµ_í•™ê¸‰ë‹¹ í•™ìƒ ìˆ˜ (ëª…)','ê³ ë“±í•™êµ_í•™ê¸‰ë‹¹ í•™ìƒ ìˆ˜ (ëª…)',
 'í•™êµêµê³¼ êµìŠµí•™ì› (ê°œ)', 'í‰ìƒì§ì—… êµìœ¡í•™ì› (ê°œ)', 'ì‚¬ì„¤í•™ì›ë‹¹ í•™ìƒìˆ˜ (ëª…)','ìœ ì¹˜ì›ìƒ ìˆ˜', 'ì´ˆë“±í•™ìƒ ìˆ˜']])
plt.show()
# ë§ì€ í†µê³„ ì†Œí”„íŠ¸ì›¨ì–´ì™€ ë¼ì´ë¸ŒëŸ¬ë¦¬ëŠ” ì ˆí¸ì„ ìë™ìœ¼ë¡œ í¬í•¨í•˜ì§€ë§Œ, 
#statsmodelsì˜ OLS (Ordinary Least Squares) í•¨ìˆ˜ëŠ” ê¸°ë³¸ì ìœ¼ë¡œ ë…ë¦½ ë³€ìˆ˜ í–‰ë ¬ ğ‘‹ì— ì ˆí¸ì„ í¬í•¨ì‹œí‚¤ì§€ ì•ŠìŠµë‹ˆë‹¤. 
#ë”°ë¼ì„œ, ì§ì ‘ ì ˆí¸ì„ ì¶”ê°€í•´ ì£¼ì–´ì•¼ í•©ë‹ˆë‹¤.
df['intercept'] = 1 #(ì ˆí¸) 
model = sm.OLS(df_p['2015'], df[['êµì›_1ì¸ë‹¹_í•™ìƒìˆ˜_ìœ ì¹˜ì›', 'êµì›_1ì¸ë‹¹_í•™ìƒìˆ˜_ì´ˆë“±í•™êµ', 'êµì›_1ì¸ë‹¹_í•™ìƒìˆ˜_ì¤‘í•™êµ', 'êµì›_1ì¸ë‹¹_í•™ìƒìˆ˜_ê³ ë“±í•™êµ',
 'ìœ ì¹˜ì›_í•™ê¸‰ë‹¹ í•™ìƒ ìˆ˜ (ëª…)', 'ì´ˆë“±í•™êµ_í•™ê¸‰ë‹¹ í•™ìƒ ìˆ˜ (ëª…)', 'ì¤‘í•™êµ_í•™ê¸‰ë‹¹ í•™ìƒ ìˆ˜ (ëª…)','ê³ ë“±í•™êµ_í•™ê¸‰ë‹¹ í•™ìƒ ìˆ˜ (ëª…)',
 'í•™êµêµê³¼ êµìŠµí•™ì› (ê°œ)', 'í‰ìƒì§ì—… êµìœ¡í•™ì› (ê°œ)', 'ì‚¬ì„¤í•™ì›ë‹¹ í•™ìƒìˆ˜ (ëª…)','ìœ ì¹˜ì›ìƒ ìˆ˜', 'ì´ˆë“±í•™ìƒ ìˆ˜']])

results = model.fit()
print(results.summary())  
'''    OLS Regression Results                                
=======================================================================================
Dep. Variable:                   2015   R-squared (uncentered):                   0.534
Model:                            OLS   Adj. R-squared (uncentered):              0.505
Method:                 Least Squares   F-statistic:                              19.00
Date:                Thu, 25 Jul 2024   Prob (F-statistic):                    3.54e-29
Time:                        11:21:26   Log-Likelihood:                         -379.98
No. Observations:                 229   AIC:                                      786.0
Df Residuals:                     216   BIC:                                      830.6
Df Model:                          13                                                  
Covariance Type:            nonrobust                                                  
=====================================================================================
                                coef    std err          t      P>|t|      [0.025      0.975]
-------------------------------------------------------------------------------------
êµì›_1ì¸ë‹¹_í•™ìƒìˆ˜_ìœ ì¹˜ì›        0.1516      0.080      1.899      0.059      -0.006       0.309
êµì›_1ì¸ë‹¹_í•™ìƒìˆ˜_ì´ˆë“±í•™êµ       0.3367      0.150      2.246      0.026       0.041       0.632
êµì›_1ì¸ë‹¹_í•™ìƒìˆ˜_ì¤‘í•™êµ        0.1471      0.112      1.317      0.189      -0.073       0.367
êµì›_1ì¸ë‹¹_í•™ìƒìˆ˜_ê³ ë“±í•™êµ      -0.0698      0.092     -0.758      0.449      -0.251       0.112
ìœ ì¹˜ì›_í•™ê¸‰ë‹¹ í•™ìƒ ìˆ˜ (ëª…)      0.0237      0.046      0.515      0.607      -0.067       0.114
ì´ˆë“±í•™êµ_í•™ê¸‰ë‹¹ í•™ìƒ ìˆ˜ (ëª…)    -0.2852      0.106     -2.696      0.008      -0.494      -0.077
ì¤‘í•™êµ_í•™ê¸‰ë‹¹ í•™ìƒ ìˆ˜ (ëª…)     -0.0852      0.062     -1.373      0.171      -0.208       0.037
ê³ ë“±í•™êµ_í•™ê¸‰ë‹¹ í•™ìƒ ìˆ˜ (ëª…)     0.0692      0.044      1.567      0.119      -0.018       0.156
í•™êµêµê³¼ êµìŠµí•™ì› (ê°œ)        -0.0004      0.000     -1.690      0.093      -0.001    7.04e-05
í‰ìƒì§ì—… êµìœ¡í•™ì› (ê°œ)         0.0026      0.002      1.053      0.294      -0.002       0.008
ì‚¬ì„¤í•™ì›ë‹¹ í•™ìƒìˆ˜ (ëª…)        -0.0005      0.001     -0.807      0.420      -0.002       0.001
ìœ ì¹˜ì›ìƒ ìˆ˜            -8.181e-05    9.7e-05     -0.844      0.400      -0.000       0.000
ì´ˆë“±í•™ìƒ ìˆ˜             1.161e-05   2.78e-05      0.418      0.677   -4.32e-05    6.64e-05
==============================================================================
Omnibus:                       58.411   Durbin-Watson:                   1.407
Prob(Omnibus):                  0.000   Jarque-Bera (JB):              103.060
Skew:                           1.345   Prob(JB):                     4.18e-23
Kurtosis:                       4.888   Cond. No.                     3.82e+04
==============================================================================

Notes:
[1] RÂ² is computed without centering (uncentered) since the model does not contain a constant.
[2] Standard Errors assume that the covariance matrix of the errors is correctly specified.
[3] The condition number is large, 3.82e+04. This might indicate that there are
strong multicollinearity or other numerical problems.'''
#%%
from statsmodels.stats.outliers_influence import variance_inflation_factor
X_train = df[['êµì›_1ì¸ë‹¹_í•™ìƒìˆ˜_ìœ ì¹˜ì›', 'êµì›_1ì¸ë‹¹_í•™ìƒìˆ˜_ì´ˆë“±í•™êµ', 'êµì›_1ì¸ë‹¹_í•™ìƒìˆ˜_ì¤‘í•™êµ', 'êµì›_1ì¸ë‹¹_í•™ìƒìˆ˜_ê³ ë“±í•™êµ',
 'ìœ ì¹˜ì›_í•™ê¸‰ë‹¹ í•™ìƒ ìˆ˜ (ëª…)', 'ì´ˆë“±í•™êµ_í•™ê¸‰ë‹¹ í•™ìƒ ìˆ˜ (ëª…)', 'ì¤‘í•™êµ_í•™ê¸‰ë‹¹ í•™ìƒ ìˆ˜ (ëª…)','ê³ ë“±í•™êµ_í•™ê¸‰ë‹¹ í•™ìƒ ìˆ˜ (ëª…)',
 'í•™êµêµê³¼ êµìŠµí•™ì› (ê°œ)', 'í‰ìƒì§ì—… êµìœ¡í•™ì› (ê°œ)', 'ì‚¬ì„¤í•™ì›ë‹¹ í•™ìƒìˆ˜ (ëª…)','ìœ ì¹˜ì›ìƒ ìˆ˜', 'ì´ˆë“±í•™ìƒ ìˆ˜']]
def feature_engineering_XbyVIF(X_train):
    vif = pd.DataFrame()
    vif['VIF_Factor'] = [variance_inflation_factor(X_train.values, i)
                         for i in range(X_train.shape[1])]
    vif['Feature'] = X_train.columns
    return vif
vif = feature_engineering_XbyVIF(X_train)
print(vif)   
'''
 VIF_Factor            Feature
0   118.583744     êµì›_1ì¸ë‹¹_í•™ìƒìˆ˜_ìœ ì¹˜ì›
1   477.173276    êµì›_1ì¸ë‹¹_í•™ìƒìˆ˜_ì´ˆë“±í•™êµ
2   239.581180     êµì›_1ì¸ë‹¹_í•™ìƒìˆ˜_ì¤‘í•™êµ
3   162.007983    êµì›_1ì¸ë‹¹_í•™ìƒìˆ˜_ê³ ë“±í•™êµ
4    90.040200   ìœ ì¹˜ì›_í•™ê¸‰ë‹¹ í•™ìƒ ìˆ˜ (ëª…)
5   569.452121  ì´ˆë“±í•™êµ_í•™ê¸‰ë‹¹ í•™ìƒ ìˆ˜ (ëª…)
6   334.279430   ì¤‘í•™êµ_í•™ê¸‰ë‹¹ í•™ìƒ ìˆ˜ (ëª…)
7   205.924685  ê³ ë“±í•™êµ_í•™ê¸‰ë‹¹ í•™ìƒ ìˆ˜ (ëª…)
8     7.631829      í•™êµêµê³¼ êµìŠµí•™ì› (ê°œ)
9     6.996400      í‰ìƒì§ì—… êµìœ¡í•™ì› (ê°œ)
10    2.133011      ì‚¬ì„¤í•™ì›ë‹¹ í•™ìƒìˆ˜ (ëª…)
11   25.967622             ìœ ì¹˜ì›ìƒ ìˆ˜
12   31.129589             ì´ˆë“±í•™ìƒ ìˆ˜    
'''
#%%
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    